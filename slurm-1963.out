PYTHONPATH
2022-09-27 12:26:47.865463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
WARNING:tensorflow:From /home/aig/.conda/envs/tfl/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
Arguments:
	         Jmax : 50
	            L : 40
	            M : 10
	     MC_trial : 50
	            N : 5
	          SNR : 90
	   batch_size : 10
	      dataset : synthetic_1_1
	 drop_percent : 0.0
	   eval_every : 1
	learning_rate : 0.01
	        model : mclr
	 model_params : (10,)
	           mu : 0
	          nit : 100
	   num_epochs : 20
	    num_iters : 1
	   num_rounds : 200
	    optimizer : fedavg
	         seed : 0
	          set : 2
	          tau : 1
	    threshold : 0.01
	      verbose : 0
Using Federated avg to Train
/home/aig/.conda/envs/tfl/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  warnings.warn('`tf.layers.dense` is deprecated and '
/home/aig/.conda/envs/tfl/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  warnings.warn('`layer.apply` is deprecated and '
2022-09-27 12:26:50.443700: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-27 12:26:50.445126: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-27 12:26:50.533639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-09-27 12:26:50.534468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-09-27 12:26:50.535158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-09-27 12:26:50.535835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:af:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-09-27 12:26:50.535881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-09-27 12:26:50.541021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-09-27 12:26:50.541126: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-09-27 12:26:50.546082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-27 12:26:50.547081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-27 12:26:50.552317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-27 12:26:50.555193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-09-27 12:26:50.564855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-09-27 12:26:50.569670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2022-09-27 12:26:50.570759: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-27 12:26:50.572506: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-27 12:26:51.077085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-09-27 12:26:51.077572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-09-27 12:26:51.077995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-09-27 12:26:51.078403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:af:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-09-27 12:26:51.078440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-09-27 12:26:51.078471: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-09-27 12:26:51.078486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-09-27 12:26:51.078500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-27 12:26:51.078514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-27 12:26:51.078527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-27 12:26:51.078541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-09-27 12:26:51.078555: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-09-27 12:26:51.081594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2022-09-27 12:26:51.081641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-09-27 13:02:13.247141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-27 13:02:13.247407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 
2022-09-27 13:02:13.247425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N N N 
2022-09-27 13:02:13.247431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N N N 
2022-09-27 13:02:13.247436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   N N N N 
2022-09-27 13:02:13.247442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   N N N N 
2022-09-27 13:02:13.250263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22430 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:18:00.0, compute capability: 8.6)
2022-09-27 13:02:13.251605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22430 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:3b:00.0, compute capability: 8.6)
2022-09-27 13:02:13.252637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 22430 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:86:00.0, compute capability: 8.6)
2022-09-27 13:02:13.253641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 22430 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6)
2022-09-27 13:02:13.259008: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)
2022-09-27 13:02:13.261634: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400000000 Hz
WARNING:tensorflow:From /home/aig/.conda/envs/tfl/lib/python3.9/site-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`
Incomplete shape.
Incomplete shape.

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================
Incomplete shape.
Incomplete shape.

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/2.40k flops)
  dense/kernel/Initializer/random_uniform (600/1.20k flops)
    dense/kernel/Initializer/random_uniform/mul (600/600 flops)
    dense/kernel/Initializer/random_uniform/sub (1/1 flops)
  dense/kernel/Regularizer/Square (600/600 flops)
  dense/kernel/Regularizer/Sum (599/599 flops)
  dense/kernel/Regularizer/mul (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/Neg (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/mul (1/1 flops)
  sparse_softmax_cross_entropy_loss/num_present/Equal (1/1 flops)

======================End of Report==========================
Training with 10/30 workers ---
sum of K (set==2) 24058 (30,)
WARNING:tensorflow:From /home/aig/NailIt/FedProx/flearn/models/synthetic/mclr.py:58: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Prefer Variable.assign which has equivalent behavior in 2.X.
2022-09-27 13:11:23.935711: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
At round 0 accuracy: 0.035977859778597784
At round 0 training accuracy: 0.035104166666666665
At round 0 training loss: 4.849575720814367
At round 1 accuracy: 0.042435424354243544
At round 1 training accuracy: 0.042395833333333334
At round 1 training loss: 2.481715108988186
At round 2 accuracy: 0.03782287822878229
At round 2 training accuracy: 0.035416666666666666
At round 2 training loss: 2.259295889437199
At round 3 accuracy: 0.03874538745387454
At round 3 training accuracy: 0.0365625
At round 3 training loss: 2.239366390928626
At round 4 accuracy: 0.03966789667896679
At round 4 training accuracy: 0.03760416666666667
At round 4 training loss: 2.237596939479311
At round 5 accuracy: 0.03966789667896679
At round 5 training accuracy: 0.03822916666666667
At round 5 training loss: 2.236975163668394
At round 6 accuracy: 0.042435424354243544
At round 6 training accuracy: 0.040729166666666664
At round 6 training loss: 2.2365187513579925
At round 7 accuracy: 0.05996309963099631
At round 7 training accuracy: 0.06010416666666667
At round 7 training loss: 2.23622513299187
At round 8 accuracy: 0.05166051660516605
At round 8 training accuracy: 0.049479166666666664
At round 8 training loss: 2.2375596934060256
At round 9 accuracy: 0.05166051660516605
At round 9 training accuracy: 0.04958333333333333
At round 9 training loss: 2.2377988782028355
At round 10 accuracy: 0.05166051660516605
At round 10 training accuracy: 0.049479166666666664
At round 10 training loss: 2.237338188464443
At round 11 accuracy: 0.05166051660516605
At round 11 training accuracy: 0.049479166666666664
At round 11 training loss: 2.2371363641073305
At round 12 accuracy: 0.05166051660516605
At round 12 training accuracy: 0.04958333333333333
At round 12 training loss: 2.236304700151086
At round 13 accuracy: 0.05166051660516605
At round 13 training accuracy: 0.04958333333333333
At round 13 training loss: 2.2368532029539345
At round 14 accuracy: 0.05166051660516605
At round 14 training accuracy: 0.04958333333333333
At round 14 training loss: 2.2374630925556023
At round 15 accuracy: 0.05166051660516605
At round 15 training accuracy: 0.0496875
At round 15 training loss: 2.2386739895741146
At round 16 accuracy: 0.05166051660516605
At round 16 training accuracy: 0.04958333333333333
At round 16 training loss: 2.2374368146806956
At round 17 accuracy: 0.05166051660516605
At round 17 training accuracy: 0.0496875
At round 17 training loss: 2.237176360314091
At round 18 accuracy: 0.05166051660516605
At round 18 training accuracy: 0.049479166666666664
At round 18 training loss: 2.236261076157292
At round 19 accuracy: 0.05166051660516605
At round 19 training accuracy: 0.04958333333333333
At round 19 training loss: 2.237703622579575
At round 20 accuracy: 0.05166051660516605
At round 20 training accuracy: 0.0496875
At round 20 training loss: 2.2375317212194203
At round 21 accuracy: 0.05166051660516605
At round 21 training accuracy: 0.04958333333333333
At round 21 training loss: 2.238722282970945
At round 22 accuracy: 0.05166051660516605
At round 22 training accuracy: 0.04958333333333333
At round 22 training loss: 2.236964451124271
At round 23 accuracy: 0.05166051660516605
At round 23 training accuracy: 0.049479166666666664
At round 23 training loss: 2.236756895457705
At round 24 accuracy: 0.05166051660516605
At round 24 training accuracy: 0.0496875
At round 24 training loss: 2.2370625521242617
At round 25 accuracy: 0.05166051660516605
At round 25 training accuracy: 0.04958333333333333
At round 25 training loss: 2.237946341310938
At round 26 accuracy: 0.05166051660516605
At round 26 training accuracy: 0.0496875
At round 26 training loss: 2.237830508177479
At round 27 accuracy: 0.05166051660516605
At round 27 training accuracy: 0.049479166666666664
At round 27 training loss: 2.2376684206724167
At round 28 accuracy: 0.05166051660516605
At round 28 training accuracy: 0.049791666666666665
At round 28 training loss: 2.2369710032393537
At round 29 accuracy: 0.05166051660516605
At round 29 training accuracy: 0.049479166666666664
At round 29 training loss: 2.236951096082727
At round 30 accuracy: 0.05166051660516605
At round 30 training accuracy: 0.049791666666666665
At round 30 training loss: 2.2370084425061942
At round 31 accuracy: 0.05166051660516605
At round 31 training accuracy: 0.04958333333333333
At round 31 training loss: 2.2375059979160627
At round 32 accuracy: 0.05166051660516605
At round 32 training accuracy: 0.0496875
At round 32 training loss: 2.23775108769536
At round 33 accuracy: 0.05166051660516605
At round 33 training accuracy: 0.0496875
At round 33 training loss: 2.237392530441284
At round 34 accuracy: 0.05166051660516605
At round 34 training accuracy: 0.049791666666666665
At round 34 training loss: 2.237444860562682
At round 35 accuracy: 0.05166051660516605
At round 35 training accuracy: 0.0496875
At round 35 training loss: 2.237197918097178
At round 36 accuracy: 0.05166051660516605
At round 36 training accuracy: 0.0496875
At round 36 training loss: 2.236689739152789
At round 37 accuracy: 0.05166051660516605
At round 37 training accuracy: 0.049479166666666664
At round 37 training loss: 2.237267818947633
At round 38 accuracy: 0.05166051660516605
At round 38 training accuracy: 0.049479166666666664
At round 38 training loss: 2.2368756519754727
At round 39 accuracy: 0.05166051660516605
At round 39 training accuracy: 0.0496875
At round 39 training loss: 2.237808122287194
At round 40 accuracy: 0.05166051660516605
At round 40 training accuracy: 0.049791666666666665
At round 40 training loss: 2.2371630733956893
At round 41 accuracy: 0.05166051660516605
At round 41 training accuracy: 0.049375
At round 41 training loss: 2.237244409074386
At round 42 accuracy: 0.05166051660516605
At round 42 training accuracy: 0.04958333333333333
At round 42 training loss: 2.236753955160578
At round 43 accuracy: 0.05166051660516605
At round 43 training accuracy: 0.04958333333333333
At round 43 training loss: 2.2372623738398154
At round 44 accuracy: 0.05166051660516605
At round 44 training accuracy: 0.049479166666666664
At round 44 training loss: 2.2375202958037455
At round 45 accuracy: 0.05166051660516605
At round 45 training accuracy: 0.0496875
At round 45 training loss: 2.2379973815133174
At round 46 accuracy: 0.05166051660516605
At round 46 training accuracy: 0.049791666666666665
At round 46 training loss: 2.2371970812479653
At round 47 accuracy: 0.05166051660516605
At round 47 training accuracy: 0.0496875
At round 47 training loss: 2.236765818769733
At round 48 accuracy: 0.05166051660516605
At round 48 training accuracy: 0.049479166666666664
At round 48 training loss: 2.2375001045068106
At round 49 accuracy: 0.05166051660516605
At round 49 training accuracy: 0.049375
At round 49 training loss: 2.236991128847003
At round 50 accuracy: 0.05166051660516605
At round 50 training accuracy: 0.04958333333333333
At round 50 training loss: 2.2381058730433385
At round 51 accuracy: 0.05166051660516605
At round 51 training accuracy: 0.04958333333333333
At round 51 training loss: 2.2379858293384314
At round 52 accuracy: 0.05166051660516605
At round 52 training accuracy: 0.04958333333333333
At round 52 training loss: 2.23687176498274
At round 53 accuracy: 0.05166051660516605
At round 53 training accuracy: 0.0496875
At round 53 training loss: 2.236846513748169
At round 54 accuracy: 0.05166051660516605
At round 54 training accuracy: 0.04958333333333333
At round 54 training loss: 2.237465347647667
At round 55 accuracy: 0.05166051660516605
At round 55 training accuracy: 0.04958333333333333
At round 55 training loss: 2.236746292387446
At round 56 accuracy: 0.05166051660516605
At round 56 training accuracy: 0.04958333333333333
At round 56 training loss: 2.2376302055766186
At round 57 accuracy: 0.05166051660516605
At round 57 training accuracy: 0.0496875
At round 57 training loss: 2.2373938103020192
At round 58 accuracy: 0.05166051660516605
At round 58 training accuracy: 0.04958333333333333
At round 58 training loss: 2.2370759621510903
At round 59 accuracy: 0.05166051660516605
At round 59 training accuracy: 0.049375
At round 59 training loss: 2.236822434961796
At round 60 accuracy: 0.05166051660516605
At round 60 training accuracy: 0.049479166666666664
At round 60 training loss: 2.236474592188994
At round 61 accuracy: 0.05166051660516605
At round 61 training accuracy: 0.049791666666666665
At round 61 training loss: 2.237355661466718
At round 62 accuracy: 0.05166051660516605
At round 62 training accuracy: 0.049791666666666665
At round 62 training loss: 2.237232238004605
At round 63 accuracy: 0.05166051660516605
At round 63 training accuracy: 0.049791666666666665
At round 63 training loss: 2.2374003327141208
At round 64 accuracy: 0.05166051660516605
At round 64 training accuracy: 0.049791666666666665
At round 64 training loss: 2.236955060909192
At round 65 accuracy: 0.05166051660516605
At round 65 training accuracy: 0.049479166666666664
At round 65 training loss: 2.2365073405454554
At round 66 accuracy: 0.05166051660516605
At round 66 training accuracy: 0.049479166666666664
At round 66 training loss: 2.236213830287258
At round 67 accuracy: 0.05166051660516605
At round 67 training accuracy: 0.04958333333333333
At round 67 training loss: 2.2375406505912543
At round 68 accuracy: 0.05166051660516605
At round 68 training accuracy: 0.049791666666666665
At round 68 training loss: 2.2377947481473286
At round 69 accuracy: 0.05166051660516605
At round 69 training accuracy: 0.049375
At round 69 training loss: 2.237344325830539
At round 70 accuracy: 0.05166051660516605
At round 70 training accuracy: 0.04958333333333333
At round 70 training loss: 2.2371369621406
At round 71 accuracy: 0.05166051660516605
At round 71 training accuracy: 0.049479166666666664
At round 71 training loss: 2.2363250046471754
At round 72 accuracy: 0.05166051660516605
At round 72 training accuracy: 0.0496875
At round 72 training loss: 2.236855922515194
At round 73 accuracy: 0.05166051660516605
At round 73 training accuracy: 0.0496875
At round 73 training loss: 2.2374628128359717
At round 74 accuracy: 0.05166051660516605
At round 74 training accuracy: 0.04958333333333333
At round 74 training loss: 2.2386748168369133
At round 75 accuracy: 0.05166051660516605
At round 75 training accuracy: 0.0496875
At round 75 training loss: 2.2374137321362895
At round 76 accuracy: 0.05166051660516605
At round 76 training accuracy: 0.0496875
At round 76 training loss: 2.237173794483145
At round 77 accuracy: 0.05166051660516605
At round 77 training accuracy: 0.0496875
At round 77 training loss: 2.236261015459895
At round 78 accuracy: 0.05166051660516605
At round 78 training accuracy: 0.0496875
At round 78 training loss: 2.2377112215260664
At round 79 accuracy: 0.05166051660516605
At round 79 training accuracy: 0.049791666666666665
At round 79 training loss: 2.2375518758346638
At round 80 accuracy: 0.05166051660516605
At round 80 training accuracy: 0.049791666666666665
At round 80 training loss: 2.2387317196528116
At round 81 accuracy: 0.05166051660516605
At round 81 training accuracy: 0.0496875
At round 81 training loss: 2.2369645714511472
At round 82 accuracy: 0.05166051660516605
At round 82 training accuracy: 0.049479166666666664
At round 82 training loss: 2.2367620296776294
At round 83 accuracy: 0.05166051660516605
At round 83 training accuracy: 0.04958333333333333
At round 83 training loss: 2.2370522276312115
At round 84 accuracy: 0.05166051660516605
At round 84 training accuracy: 0.0496875
At round 84 training loss: 2.2379360514630875
At round 85 accuracy: 0.05166051660516605
At round 85 training accuracy: 0.049791666666666665
At round 85 training loss: 2.2378222905347744
At round 86 accuracy: 0.05166051660516605
At round 86 training accuracy: 0.0496875
At round 86 training loss: 2.2376693690071505
At round 87 accuracy: 0.05166051660516605
At round 87 training accuracy: 0.04958333333333333
At round 87 training loss: 2.236985276316603
At round 88 accuracy: 0.05166051660516605
At round 88 training accuracy: 0.049479166666666664
At round 88 training loss: 2.236957345927755
At round 89 accuracy: 0.05166051660516605
At round 89 training accuracy: 0.0496875
At round 89 training loss: 2.237016978189349
At round 90 accuracy: 0.05166051660516605
At round 90 training accuracy: 0.04958333333333333
At round 90 training loss: 2.237510824675361
At round 91 accuracy: 0.05166051660516605
At round 91 training accuracy: 0.0496875
At round 91 training loss: 2.2377311658362546
At round 92 accuracy: 0.05166051660516605
At round 92 training accuracy: 0.049479166666666664
At round 92 training loss: 2.2373839945842824
At round 93 accuracy: 0.05166051660516605
At round 93 training accuracy: 0.0496875
At round 93 training loss: 2.237445644438267
At round 94 accuracy: 0.05166051660516605
At round 94 training accuracy: 0.04958333333333333
At round 94 training loss: 2.2371890203406415
At round 95 accuracy: 0.05166051660516605
At round 95 training accuracy: 0.04958333333333333
At round 95 training loss: 2.236699693252643
At round 96 accuracy: 0.05166051660516605
At round 96 training accuracy: 0.04958333333333333
At round 96 training loss: 2.23728517147402
At round 97 accuracy: 0.05166051660516605
At round 97 training accuracy: 0.049375
At round 97 training loss: 2.236892605945468
At round 98 accuracy: 0.05166051660516605
At round 98 training accuracy: 0.049791666666666665
At round 98 training loss: 2.237811981414755
At round 99 accuracy: 0.05166051660516605
At round 99 training accuracy: 0.0496875
At round 99 training loss: 2.237161959335208
At round 100 accuracy: 0.05166051660516605
At round 100 training accuracy: 0.0496875
At round 100 training loss: 2.2372319368769724
At round 101 accuracy: 0.05166051660516605
At round 101 training accuracy: 0.04958333333333333
At round 101 training loss: 2.2367317893107734
At round 102 accuracy: 0.05166051660516605
At round 102 training accuracy: 0.049479166666666664
At round 102 training loss: 2.2372380145142476
At round 103 accuracy: 0.05166051660516605
At round 103 training accuracy: 0.049479166666666664
At round 103 training loss: 2.2375200399259727
At round 104 accuracy: 0.05166051660516605
At round 104 training accuracy: 0.04958333333333333
At round 104 training loss: 2.2380023513237637
At round 105 accuracy: 0.05166051660516605
At round 105 training accuracy: 0.049791666666666665
At round 105 training loss: 2.2372147339085737
At round 106 accuracy: 0.05166051660516605
At round 106 training accuracy: 0.049479166666666664
At round 106 training loss: 2.236790037676692
At round 107 accuracy: 0.05166051660516605
At round 107 training accuracy: 0.0496875
At round 107 training loss: 2.2375185171763103
At round 108 accuracy: 0.05166051660516605
At round 108 training accuracy: 0.049791666666666665
At round 108 training loss: 2.2369935286293425
At round 109 accuracy: 0.05166051660516605
At round 109 training accuracy: 0.0496875
At round 109 training loss: 2.238093820263942
At round 110 accuracy: 0.05166051660516605
At round 110 training accuracy: 0.049791666666666665
At round 110 training loss: 2.2379724430541197
At round 111 accuracy: 0.05166051660516605
At round 111 training accuracy: 0.049375
At round 111 training loss: 2.236851573313276
At round 112 accuracy: 0.05166051660516605
At round 112 training accuracy: 0.0496875
At round 112 training loss: 2.2368227276951074
At round 113 accuracy: 0.05166051660516605
At round 113 training accuracy: 0.049791666666666665
At round 113 training loss: 2.237445674886306
At round 114 accuracy: 0.05166051660516605
At round 114 training accuracy: 0.04958333333333333
At round 114 training loss: 2.2367589030911526
At round 115 accuracy: 0.05166051660516605
At round 115 training accuracy: 0.04958333333333333
At round 115 training loss: 2.237656435246269
At round 116 accuracy: 0.05166051660516605
At round 116 training accuracy: 0.04958333333333333
At round 116 training loss: 2.2373958977311847
At round 117 accuracy: 0.05166051660516605
At round 117 training accuracy: 0.04958333333333333
At round 117 training loss: 2.2370882592350245
At round 118 accuracy: 0.05166051660516605
At round 118 training accuracy: 0.0496875
At round 118 training loss: 2.236828699633479
At round 119 accuracy: 0.05166051660516605
At round 119 training accuracy: 0.0496875
At round 119 training loss: 2.236464923992753
At round 120 accuracy: 0.05166051660516605
At round 120 training accuracy: 0.04958333333333333
At round 120 training loss: 2.2373312204082807
At round 121 accuracy: 0.05166051660516605
At round 121 training accuracy: 0.0496875
At round 121 training loss: 2.237220286404093
At round 122 accuracy: 0.05166051660516605
At round 122 training accuracy: 0.049375
At round 122 training loss: 2.23739092340072
At round 123 accuracy: 0.05166051660516605
At round 123 training accuracy: 0.04958333333333333
At round 123 training loss: 2.2369628868500393
At round 124 accuracy: 0.05166051660516605
At round 124 training accuracy: 0.04958333333333333
At round 124 training loss: 2.236522149220109
At round 125 accuracy: 0.05166051660516605
At round 125 training accuracy: 0.04958333333333333
At round 125 training loss: 2.2362172927459083
At round 126 accuracy: 0.05166051660516605
At round 126 training accuracy: 0.04958333333333333
At round 126 training loss: 2.237551677674055
At round 127 accuracy: 0.05166051660516605
At round 127 training accuracy: 0.04958333333333333
At round 127 training loss: 2.2377893592913947
At round 128 accuracy: 0.05166051660516605
At round 128 training accuracy: 0.0496875
At round 128 training loss: 2.2373113872855903
At round 129 accuracy: 0.05166051660516605
At round 129 training accuracy: 0.049479166666666664
At round 129 training loss: 2.2371266112228234
At round 130 accuracy: 0.05166051660516605
At round 130 training accuracy: 0.0496875
At round 130 training loss: 2.236317692771554
At round 131 accuracy: 0.05166051660516605
At round 131 training accuracy: 0.0496875
At round 131 training loss: 2.2368610355754694
At round 132 accuracy: 0.05166051660516605
At round 132 training accuracy: 0.0496875
At round 132 training loss: 2.237472643231352
At round 133 accuracy: 0.05166051660516605
At round 133 training accuracy: 0.04958333333333333
At round 133 training loss: 2.238686131288608
At round 134 accuracy: 0.05166051660516605
At round 134 training accuracy: 0.049791666666666665
At round 134 training loss: 2.237439740523696
At round 135 accuracy: 0.05166051660516605
At round 135 training accuracy: 0.049791666666666665
At round 135 training loss: 2.2371706757694483
At round 136 accuracy: 0.05166051660516605
At round 136 training accuracy: 0.04958333333333333
At round 136 training loss: 2.236255162457625
At round 137 accuracy: 0.05166051660516605
At round 137 training accuracy: 0.04958333333333333
At round 137 training loss: 2.2377046949168045
At round 138 accuracy: 0.05166051660516605
At round 138 training accuracy: 0.0496875
At round 138 training loss: 2.2375350164125365
At round 139 accuracy: 0.05166051660516605
At round 139 training accuracy: 0.049479166666666664
At round 139 training loss: 2.2387229585647583
At round 140 accuracy: 0.05166051660516605
At round 140 training accuracy: 0.0496875
At round 140 training loss: 2.236958332931002
At round 141 accuracy: 0.05166051660516605
At round 141 training accuracy: 0.04958333333333333
At round 141 training loss: 2.236768262361487
At round 142 accuracy: 0.05166051660516605
At round 142 training accuracy: 0.0496875
At round 142 training loss: 2.2370693261921404
At round 143 accuracy: 0.05166051660516605
At round 143 training accuracy: 0.0496875
At round 143 training loss: 2.237935003315409
At round 144 accuracy: 0.05166051660516605
At round 144 training accuracy: 0.049791666666666665
At round 144 training loss: 2.237809078420202
At round 145 accuracy: 0.05166051660516605
At round 145 training accuracy: 0.049791666666666665
At round 145 training loss: 2.2376575305561226
At round 146 accuracy: 0.05166051660516605
At round 146 training accuracy: 0.0496875
At round 146 training loss: 2.236984903588891
At round 147 accuracy: 0.05166051660516605
At round 147 training accuracy: 0.04958333333333333
At round 147 training loss: 2.2369447437177103
At round 148 accuracy: 0.05166051660516605
At round 148 training accuracy: 0.049479166666666664
At round 148 training loss: 2.2370064495503903
At round 149 accuracy: 0.05166051660516605
At round 149 training accuracy: 0.049791666666666665
At round 149 training loss: 2.2375128476073343
At round 150 accuracy: 0.05166051660516605
At round 150 training accuracy: 0.049791666666666665
At round 150 training loss: 2.2377537728846075
At round 151 accuracy: 0.05166051660516605
At round 151 training accuracy: 0.04958333333333333
At round 151 training loss: 2.2373976006607212
At round 152 accuracy: 0.05166051660516605
At round 152 training accuracy: 0.0496875
At round 152 training loss: 2.237438926299413
At round 153 accuracy: 0.05166051660516605
At round 153 training accuracy: 0.0496875
At round 153 training loss: 2.237186232507229
At round 154 accuracy: 0.05166051660516605
At round 154 training accuracy: 0.0496875
At round 154 training loss: 2.2366821055114268
At round 155 accuracy: 0.05166051660516605
At round 155 training accuracy: 0.04958333333333333
At round 155 training loss: 2.237264771237969
At round 156 accuracy: 0.05166051660516605
At round 156 training accuracy: 0.04958333333333333
At round 156 training loss: 2.2368875244508186
At round 157 accuracy: 0.05166051660516605
At round 157 training accuracy: 0.0496875
At round 157 training loss: 2.237806835224231
At round 158 accuracy: 0.05166051660516605
At round 158 training accuracy: 0.04958333333333333
At round 158 training loss: 2.2371698034058016
At round 159 accuracy: 0.05166051660516605
At round 159 training accuracy: 0.049791666666666665
At round 159 training loss: 2.237265840222438
At round 160 accuracy: 0.05166051660516605
At round 160 training accuracy: 0.0496875
At round 160 training loss: 2.2367683808753887
At round 161 accuracy: 0.05166051660516605
At round 161 training accuracy: 0.049375
At round 161 training loss: 2.237253469576438
At round 162 accuracy: 0.05166051660516605
At round 162 training accuracy: 0.04958333333333333
At round 162 training loss: 2.2375250160694122
At round 163 accuracy: 0.05166051660516605
At round 163 training accuracy: 0.0496875
At round 163 training loss: 2.237986223871509
At round 164 accuracy: 0.05166051660516605
At round 164 training accuracy: 0.04958333333333333
At round 164 training loss: 2.237201470707854
At round 165 accuracy: 0.05166051660516605
At round 165 training accuracy: 0.04958333333333333
At round 165 training loss: 2.236761763940255
At round 166 accuracy: 0.05166051660516605
At round 166 training accuracy: 0.04958333333333333
At round 166 training loss: 2.2374947725733123
At round 167 accuracy: 0.05166051660516605
At round 167 training accuracy: 0.049479166666666664
At round 167 training loss: 2.237004662454128
At round 168 accuracy: 0.05166051660516605
At round 168 training accuracy: 0.049791666666666665
At round 168 training loss: 2.238121015528838
At round 169 accuracy: 0.05166051660516605
At round 169 training accuracy: 0.04958333333333333
At round 169 training loss: 2.2379864894598724
At round 170 accuracy: 0.05166051660516605
At round 170 training accuracy: 0.049479166666666664
At round 170 training loss: 2.2368725895881654
At round 171 accuracy: 0.05166051660516605
At round 171 training accuracy: 0.049791666666666665
At round 171 training loss: 2.236835151563088
At round 172 accuracy: 0.05166051660516605
At round 172 training accuracy: 0.0496875
At round 172 training loss: 2.2374417113512752
At round 173 accuracy: 0.05166051660516605
At round 173 training accuracy: 0.04927083333333333
At round 173 training loss: 2.236746734455228
At round 174 accuracy: 0.05166051660516605
At round 174 training accuracy: 0.049791666666666665
At round 174 training loss: 2.237630422661702
At round 175 accuracy: 0.05166051660516605
At round 175 training accuracy: 0.0496875
At round 175 training loss: 2.237383942132195
At round 176 accuracy: 0.05166051660516605
At round 176 training accuracy: 0.04958333333333333
At round 176 training loss: 2.237065570851167
At round 177 accuracy: 0.05166051660516605
At round 177 training accuracy: 0.049479166666666664
At round 177 training loss: 2.236841456517577
At round 178 accuracy: 0.05166051660516605
At round 178 training accuracy: 0.049375
At round 178 training loss: 2.236486250683665
At round 179 accuracy: 0.05166051660516605
At round 179 training accuracy: 0.04958333333333333
At round 179 training loss: 2.2373483403772116
At round 180 accuracy: 0.05166051660516605
At round 180 training accuracy: 0.0496875
At round 180 training loss: 2.23721794500947
At round 181 accuracy: 0.05166051660516605
At round 181 training accuracy: 0.0496875
At round 181 training loss: 2.237386153936386
At round 182 accuracy: 0.05166051660516605
At round 182 training accuracy: 0.049479166666666664
At round 182 training loss: 2.2369586141904194
At round 183 accuracy: 0.05166051660516605
At round 183 training accuracy: 0.04958333333333333
At round 183 training loss: 2.2365140933543444
At round 184 accuracy: 0.05166051660516605
At round 184 training accuracy: 0.04958333333333333
At round 184 training loss: 2.2362209522475798
At round 185 accuracy: 0.05166051660516605
At round 185 training accuracy: 0.0496875
At round 185 training loss: 2.237543348222971
At round 186 accuracy: 0.05166051660516605
At round 186 training accuracy: 0.04958333333333333
At round 186 training loss: 2.2378131024787824
At round 187 accuracy: 0.05166051660516605
At round 187 training accuracy: 0.0496875
At round 187 training loss: 2.23734903867046
At round 188 accuracy: 0.05166051660516605
At round 188 training accuracy: 0.049791666666666665
At round 188 training loss: 2.2371264940996967
At round 189 accuracy: 0.05166051660516605
At round 189 training accuracy: 0.049791666666666665
At round 189 training loss: 2.236318924377362
At round 190 accuracy: 0.05166051660516605
At round 190 training accuracy: 0.0496875
At round 190 training loss: 2.2368497241288425
At round 191 accuracy: 0.05166051660516605
At round 191 training accuracy: 0.0496875
At round 191 training loss: 2.2374729124456643
At round 192 accuracy: 0.05166051660516605
At round 192 training accuracy: 0.049479166666666664
At round 192 training loss: 2.2386651361733674
At round 193 accuracy: 0.05166051660516605
At round 193 training accuracy: 0.049791666666666665
At round 193 training loss: 2.2374256656070552
At round 194 accuracy: 0.05166051660516605
At round 194 training accuracy: 0.0496875
At round 194 training loss: 2.2371781934052706
At round 195 accuracy: 0.05166051660516605
At round 195 training accuracy: 0.0496875
At round 195 training loss: 2.236258969505628
At round 196 accuracy: 0.05166051660516605
At round 196 training accuracy: 0.0496875
At round 196 training loss: 2.237717419490218
At round 197 accuracy: 0.05166051660516605
At round 197 training accuracy: 0.0496875
At round 197 training loss: 2.237528250962496
At round 198 accuracy: 0.05166051660516605
At round 198 training accuracy: 0.049479166666666664
At round 198 training loss: 2.2387175547579923
At round 199 accuracy: 0.05166051660516605
At round 199 training accuracy: 0.0496875
At round 199 training loss: 2.2369525526463985
At round 200 accuracy: 0.05166051660516605
At round 200 training accuracy: 0.049479166666666664
