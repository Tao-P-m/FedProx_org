PYTHONPATH
2022-10-20 08:21:41.796805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
WARNING:tensorflow:From /home/aig/.conda/envs/tfl/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
Arguments:
	         Jmax : 50
	            L : 40
	            M : 10
	     MC_trial : 50
	            N : 5
	          SNR : 90
	   batch_size : 10
	      dataset : synthetic_1_1
	 drop_percent : 0.0
	   eval_every : 1
	learning_rate : 0.01
	        model : mclr
	 model_params : (10,)
	           mu : 0
	          nit : 100
	   num_epochs : 20
	    num_iters : 1
	   num_rounds : 200
	    optimizer : fedavg
	         seed : 0
	          set : 2
	          tau : 1
	    threshold : 0.01
	      verbose : 0
Using Federated avg to Train
/home/aig/.conda/envs/tfl/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  warnings.warn('`tf.layers.dense` is deprecated and '
/home/aig/.conda/envs/tfl/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  warnings.warn('`layer.apply` is deprecated and '
2022-10-20 08:21:44.207630: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-10-20 08:21:44.208936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-10-20 08:21:44.320571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 08:21:44.321252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 08:21:44.321859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 08:21:44.322455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:af:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 08:21:44.322492: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-10-20 08:21:44.327047: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-10-20 08:21:44.327136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-10-20 08:21:44.331569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-10-20 08:21:44.332486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-10-20 08:21:44.337146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-10-20 08:21:44.339630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-10-20 08:21:44.348080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-10-20 08:21:44.352374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2022-10-20 08:21:44.353029: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-20 08:21:44.354708: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-10-20 08:21:45.006175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 08:21:45.006650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 08:21:45.007065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 08:21:45.007468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:af:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 08:21:45.007503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-10-20 08:21:45.007531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-10-20 08:21:45.007546: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-10-20 08:21:45.007561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-10-20 08:21:45.007575: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-10-20 08:21:45.007590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-10-20 08:21:45.007604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-10-20 08:21:45.007618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-10-20 08:21:45.010598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2022-10-20 08:21:45.010640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-10-20 08:56:49.448009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-10-20 08:56:49.448331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 
2022-10-20 08:56:49.448348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N N N 
2022-10-20 08:56:49.448353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N N N 
2022-10-20 08:56:49.448357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   N N N N 
2022-10-20 08:56:49.448362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   N N N N 
2022-10-20 08:56:49.451352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22430 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:18:00.0, compute capability: 8.6)
2022-10-20 08:56:49.452614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22430 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:3b:00.0, compute capability: 8.6)
2022-10-20 08:56:49.453640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 22430 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:86:00.0, compute capability: 8.6)
2022-10-20 08:56:49.454674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 22430 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6)
2022-10-20 08:56:49.459508: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)
2022-10-20 08:56:49.461818: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400000000 Hz
WARNING:tensorflow:From /home/aig/.conda/envs/tfl/lib/python3.9/site-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`
Incomplete shape.
Incomplete shape.

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================
Incomplete shape.
Incomplete shape.

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/2.40k flops)
  dense/kernel/Initializer/random_uniform (600/1.20k flops)
    dense/kernel/Initializer/random_uniform/mul (600/600 flops)
    dense/kernel/Initializer/random_uniform/sub (1/1 flops)
  dense/kernel/Regularizer/Square (600/600 flops)
  dense/kernel/Regularizer/Sum (599/599 flops)
  dense/kernel/Regularizer/mul (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/Neg (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/mul (1/1 flops)
  sparse_softmax_cross_entropy_loss/num_present/Equal (1/1 flops)

======================End of Report==========================
Training with 10/30 workers ---
sum of K (set==2) 24058 (30,)
try user num: 30, feasible:False None
try user num: 29, feasible:False None
try user num: 28, feasible:False None
try user num: 27, feasible:False None
try user num: 26, feasible:False None
try user num: 25, feasible:False None
try user num: 24, feasible:False None
try user num: 23, feasible:False None
try user num: 22, feasible:False None
try user num: 21, feasible:False None
try user num: 20, feasible:False None
try user num: 19, feasible:False None
try user num: 18, feasible:False None
try user num: 17, feasible:False None
try user num: 16, feasible:False None
try user num: 15, feasible:False None
try user num: 14, feasible:False None
try user num: 13, feasible:False None
try user num: 12, feasible:False None
try user num: 11, feasible:False None
try user num: 10, feasible:True [ 0.249832+0.j       -0.225892-0.150309j  0.772145-0.046531j
  0.064085+0.074851j -0.130382+0.488755j]
WARNING:tensorflow:From /home/aig/NailIt/FedProx/flearn/models/synthetic/mclr.py:58: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Prefer Variable.assign which has equivalent behavior in 2.X.
2022-10-20 09:05:51.939407: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
At round 0 accuracy: 0.035977859778597784
At round 0 training accuracy: 0.035104166666666665
At round 0 training loss: 4.849575720814367
At round 1 accuracy: 0.035977859778597784
At round 1 training accuracy: 0.03875
At round 1 training loss: 3.5366157313560445
At round 2 accuracy: 0.04428044280442804
At round 2 training accuracy: 0.04041666666666666
At round 2 training loss: 3.7477335494197903
At round 3 accuracy: 0.06365313653136531
At round 3 training accuracy: 0.058333333333333334
At round 3 training loss: 4.007516639015327
At round 4 accuracy: 0.0996309963099631
At round 4 training accuracy: 0.094375
At round 4 training loss: 2.934958251727124
At round 5 accuracy: 0.1070110701107011
At round 5 training accuracy: 0.105625
At round 5 training loss: 2.8524006580685577
At round 6 accuracy: 0.10239852398523985
At round 6 training accuracy: 0.0925
At round 6 training loss: 2.915061375175913
At round 7 accuracy: 0.12269372693726938
At round 7 training accuracy: 0.116875
At round 7 training loss: 2.8761353452627856
At round 8 accuracy: 0.11900369003690037
At round 8 training accuracy: 0.11135416666666667
At round 8 training loss: 2.840519739501178
At round 9 accuracy: 0.13468634686346864
At round 9 training accuracy: 0.13
At round 9 training loss: 2.0822199847735465
At round 10 accuracy: 0.16420664206642066
At round 10 training accuracy: 0.15145833333333333
At round 10 training loss: 2.6092395650719604
At round 11 accuracy: 0.17804428044280443
At round 11 training accuracy: 0.159375
At round 11 training loss: 2.869920836475988
At round 12 accuracy: 0.3800738007380074
At round 12 training accuracy: 0.368125
At round 12 training loss: 1.7788415812204281
At round 13 accuracy: 0.4566420664206642
At round 13 training accuracy: 0.46791666666666665
At round 13 training loss: 1.6664453738493223
At round 14 accuracy: 0.522140221402214
At round 14 training accuracy: 0.5263541666666667
At round 14 training loss: 1.3286971169461808
At round 15 accuracy: 0.4870848708487085
At round 15 training accuracy: 0.4970833333333333
At round 15 training loss: 1.500255115404725
At round 16 accuracy: 0.4806273062730627
At round 16 training accuracy: 0.49322916666666666
At round 16 training loss: 1.7988873450520138
At round 17 accuracy: 0.48616236162361626
At round 17 training accuracy: 0.49635416666666665
At round 17 training loss: 1.6808426603581756
At round 18 accuracy: 0.272140221402214
At round 18 training accuracy: 0.2713541666666667
At round 18 training loss: 1.798409895291552
At round 19 accuracy: 0.23616236162361623
At round 19 training accuracy: 0.23458333333333334
At round 19 training loss: 1.8895774367948373
At round 20 accuracy: 0.22140221402214022
At round 20 training accuracy: 0.21677083333333333
At round 20 training loss: 2.113705126661807
At round 21 accuracy: 0.22047970479704798
At round 21 training accuracy: 0.20854166666666665
At round 21 training loss: 2.3585051072450978
At round 22 accuracy: 0.22878228782287824
At round 22 training accuracy: 0.21229166666666666
At round 22 training loss: 2.6620056850214797
At round 23 accuracy: 0.22509225092250923
At round 23 training accuracy: 0.211875
At round 23 training loss: 2.5921372663695363
At round 24 accuracy: 0.22878228782287824
At round 24 training accuracy: 0.22
At round 24 training loss: 2.8851321167498827
At round 25 accuracy: 0.235239852398524
At round 25 training accuracy: 0.22270833333333334
At round 25 training loss: 2.9024187288153915
At round 26 accuracy: 0.23616236162361623
At round 26 training accuracy: 0.22791666666666666
At round 26 training loss: 2.874064765156557
At round 27 accuracy: 0.23247232472324722
At round 27 training accuracy: 0.22177083333333333
At round 27 training loss: 3.099561010788505
At round 28 accuracy: 0.23431734317343172
At round 28 training accuracy: 0.23135416666666667
At round 28 training loss: 2.047832498041292
At round 29 accuracy: 0.492619926199262
At round 29 training accuracy: 0.49802083333333336
At round 29 training loss: 1.6349559302348644
At round 30 accuracy: 0.5138376383763837
At round 30 training accuracy: 0.5234375
At round 30 training loss: 1.4217489125144978
At round 31 accuracy: 0.5276752767527675
At round 31 training accuracy: 0.5330208333333334
At round 31 training loss: 1.1497481083249053
At round 32 accuracy: 0.6153136531365314
At round 32 training accuracy: 0.6254166666666666
At round 32 training loss: 0.9118180039462944
At round 33 accuracy: 0.6466789667896679
At round 33 training accuracy: 0.6792708333333334
At round 33 training loss: 0.8561594038487722
At round 34 accuracy: 0.6531365313653137
At round 34 training accuracy: 0.6797916666666667
At round 34 training loss: 0.8434432868411144
At round 35 accuracy: 0.5996309963099631
At round 35 training accuracy: 0.615625
At round 35 training loss: 0.9199897287537654
At round 36 accuracy: 0.6503690036900369
At round 36 training accuracy: 0.6694791666666666
At round 36 training loss: 0.9572837318278228
At round 37 accuracy: 0.6595940959409594
At round 37 training accuracy: 0.6995833333333333
At round 37 training loss: 0.8238977660145611
At round 38 accuracy: 0.5950184501845018
At round 38 training accuracy: 0.614375
At round 38 training loss: 0.8914007300635179
At round 39 accuracy: 0.6559040590405905
At round 39 training accuracy: 0.6966666666666667
At round 39 training loss: 0.9127291092680146
At round 40 accuracy: 0.5581180811808119
At round 40 training accuracy: 0.5805208333333334
At round 40 training loss: 1.0562814321446543
At round 41 accuracy: 0.6217712177121771
At round 41 training accuracy: 0.6470833333333333
At round 41 training loss: 0.8523630425008014
At round 42 accuracy: 0.5359778597785978
At round 42 training accuracy: 0.5483333333333333
At round 42 training loss: 1.1648343079987293
At round 43 accuracy: 0.5230627306273062
At round 43 training accuracy: 0.5320833333333334
At round 43 training loss: 1.2746569930529221
At round 44 accuracy: 0.559040590405904
At round 44 training accuracy: 0.5766666666666667
At round 44 training loss: 1.0139773843623698
At round 45 accuracy: 0.5295202952029521
At round 45 training accuracy: 0.5369791666666667
At round 45 training loss: 1.242266174692971
At round 46 accuracy: 0.5267527675276753
At round 46 training accuracy: 0.5353125
At round 46 training loss: 1.3169819243050491
At round 47 accuracy: 0.5230627306273062
At round 47 training accuracy: 0.539375
At round 47 training loss: 1.4773057207791134
At round 48 accuracy: 0.522140221402214
At round 48 training accuracy: 0.5355208333333333
At round 48 training loss: 1.4630034542363137
At round 49 accuracy: 0.5285977859778598
At round 49 training accuracy: 0.5395833333333333
At round 49 training loss: 1.3886565905172998
At round 50 accuracy: 0.5396678966789668
At round 50 training accuracy: 0.5467708333333333
At round 50 training loss: 1.2699646886903793
At round 51 accuracy: 0.5304428044280443
At round 51 training accuracy: 0.5467708333333333
At round 51 training loss: 1.235407182048075
At round 52 accuracy: 0.5618081180811808
At round 52 training accuracy: 0.5735416666666666
At round 52 training loss: 1.0743930358470728
At round 53 accuracy: 0.6116236162361623
At round 53 training accuracy: 0.6228125
At round 53 training loss: 0.9107396255014464
At round 54 accuracy: 0.6900369003690037
At round 54 training accuracy: 0.7177083333333333
At round 54 training loss: 0.7407121960399672
At round 55 accuracy: 0.6429889298892989
At round 55 training accuracy: 0.6632291666666666
At round 55 training loss: 0.8022949012042955
At round 56 accuracy: 0.6881918819188192
At round 56 training accuracy: 0.7241666666666666
At round 56 training loss: 0.7302605174280082
At round 57 accuracy: 0.7038745387453874
At round 57 training accuracy: 0.7004166666666667
At round 57 training loss: 0.7604117874847725
At round 58 accuracy: 0.6928044280442804
At round 58 training accuracy: 0.7254166666666667
At round 58 training loss: 0.7736716573126614
At round 59 accuracy: 0.6162361623616236
At round 59 training accuracy: 0.6225
At round 59 training loss: 0.8771653728140518
At round 60 accuracy: 0.6153136531365314
At round 60 training accuracy: 0.6217708333333334
At round 60 training loss: 0.9135338436672464
At round 61 accuracy: 0.6688191881918819
At round 61 training accuracy: 0.6894791666666666
At round 61 training loss: 0.847562163247106
At round 62 accuracy: 0.6245387453874539
At round 62 training accuracy: 0.63625
At round 62 training loss: 0.9340806409879587
At round 63 accuracy: 0.698339483394834
At round 63 training accuracy: 0.7285416666666666
At round 63 training loss: 0.7749489579924072
At round 64 accuracy: 0.7084870848708487
At round 64 training accuracy: 0.73875
At round 64 training loss: 0.7093868155886108
At round 65 accuracy: 0.6928044280442804
At round 65 training accuracy: 0.7155208333333334
At round 65 training loss: 0.7225554045553629
At round 66 accuracy: 0.5839483394833949
At round 66 training accuracy: 0.5938541666666667
At round 66 training loss: 0.9761967177169087
At round 67 accuracy: 0.5544280442804428
At round 67 training accuracy: 0.56375
At round 67 training loss: 1.214348164634624
At round 68 accuracy: 0.6134686346863468
At round 68 training accuracy: 0.6201041666666667
At round 68 training loss: 0.8696359089529142
At round 69 accuracy: 0.672509225092251
At round 69 training accuracy: 0.6959375
At round 69 training loss: 0.7288758866582066
At round 70 accuracy: 0.6678966789667896
At round 70 training accuracy: 0.6961458333333334
At round 70 training loss: 0.736038531633094
At round 71 accuracy: 0.5885608856088561
At round 71 training accuracy: 0.605625
At round 71 training loss: 0.9053235072130338
At round 72 accuracy: 0.6309963099630996
At round 72 training accuracy: 0.6538541666666666
At round 72 training loss: 0.7755737278563902
At round 73 accuracy: 0.6771217712177122
At round 73 training accuracy: 0.7041666666666667
At round 73 training loss: 0.7006429626179549
At round 74 accuracy: 0.6070110701107011
At round 74 training accuracy: 0.6177083333333333
At round 74 training loss: 0.8567092971418363
At round 75 accuracy: 0.6070110701107011
At round 75 training accuracy: 0.6257291666666667
At round 75 training loss: 0.831408252301626
At round 76 accuracy: 0.6632841328413284
At round 76 training accuracy: 0.6902083333333333
At round 76 training loss: 0.718241522385118
At round 77 accuracy: 0.6448339483394834
At round 77 training accuracy: 0.6746875
At round 77 training loss: 0.7465022224917387
At round 78 accuracy: 0.6005535055350554
At round 78 training accuracy: 0.6202083333333334
At round 78 training loss: 0.8606113722175359
At round 79 accuracy: 0.5904059040590406
At round 79 training accuracy: 0.6078125
At round 79 training loss: 0.9065503241835783
At round 80 accuracy: 0.6319188191881919
At round 80 training accuracy: 0.6404166666666666
At round 80 training loss: 0.8256281520674627
At round 81 accuracy: 0.5691881918819188
At round 81 training accuracy: 0.5889583333333334
At round 81 training loss: 1.0153772269247565
At round 82 accuracy: 0.5876383763837638
At round 82 training accuracy: 0.6046875
At round 82 training loss: 0.9520104276555745
At round 83 accuracy: 0.6586715867158671
At round 83 training accuracy: 0.679375
At round 83 training loss: 0.7437527834546441
At round 84 accuracy: 0.698339483394834
At round 84 training accuracy: 0.7310416666666667
At round 84 training loss: 0.6771589246780301
At round 85 accuracy: 0.6872693726937269
At round 85 training accuracy: 0.7114583333333333
At round 85 training loss: 0.6889947386695228
At round 86 accuracy: 0.7084870848708487
At round 86 training accuracy: 0.7454166666666666
At round 86 training loss: 0.6363990569580347
At round 87 accuracy: 0.5608856088560885
At round 87 training accuracy: 0.5821875
At round 87 training loss: 1.122813364539761
At round 88 accuracy: 0.5433579335793358
At round 88 training accuracy: 0.5632291666666667
At round 88 training loss: 1.514777819746329
At round 89 accuracy: 0.5562730627306273
At round 89 training accuracy: 0.5764583333333333
At round 89 training loss: 1.175248637831149
At round 90 accuracy: 0.5738007380073801
At round 90 training accuracy: 0.5921875
At round 90 training loss: 1.006852888855307
At round 91 accuracy: 0.5636531365313653
At round 91 training accuracy: 0.5822916666666667
At round 91 training loss: 1.1155189586205718
At round 92 accuracy: 0.5802583025830258
At round 92 training accuracy: 0.595
At round 92 training loss: 1.0122297640466906
At round 93 accuracy: 0.5867158671586716
At round 93 training accuracy: 0.6091666666666666
At round 93 training loss: 0.9511943750830445
At round 94 accuracy: 0.6033210332103321
At round 94 training accuracy: 0.6263541666666667
At round 94 training loss: 0.8551621069318692
At round 95 accuracy: 0.6300738007380073
At round 95 training accuracy: 0.6473958333333333
At round 95 training loss: 0.7954150128564409
At round 96 accuracy: 0.5710332103321033
At round 96 training accuracy: 0.5896875
At round 96 training loss: 1.0652358640198751
At round 97 accuracy: 0.559040590405904
At round 97 training accuracy: 0.5790625
At round 97 training loss: 1.24323649074339
At round 98 accuracy: 0.5562730627306273
At round 98 training accuracy: 0.5722916666666666
At round 98 training loss: 1.9155584921055318
At round 99 accuracy: 0.5535055350553506
At round 99 training accuracy: 0.5717708333333333
At round 99 training loss: 2.1575757492438425
At round 100 accuracy: 0.5544280442804428
At round 100 training accuracy: 0.5764583333333333
At round 100 training loss: 1.9043301517209814
At round 101 accuracy: 0.5571955719557196
At round 101 training accuracy: 0.5771875
At round 101 training loss: 1.7110653164004908
At round 102 accuracy: 0.5608856088560885
At round 102 training accuracy: 0.5822916666666667
At round 102 training loss: 2.0325250293605497
At round 103 accuracy: 0.5581180811808119
At round 103 training accuracy: 0.5833333333333334
At round 103 training loss: 2.027180509799121
At round 104 accuracy: 0.5682656826568265
At round 104 training accuracy: 0.5897916666666667
At round 104 training loss: 1.2260246416581018
At round 105 accuracy: 0.5581180811808119
At round 105 training accuracy: 0.5803125
At round 105 training loss: 1.6330674501267883
At round 106 accuracy: 0.5627306273062731
At round 106 training accuracy: 0.5885416666666666
At round 106 training loss: 1.4781961483626704
At round 107 accuracy: 0.5562730627306273
At round 107 training accuracy: 0.5846875
At round 107 training loss: 1.8415339235588908
At round 108 accuracy: 0.5627306273062731
At round 108 training accuracy: 0.5872916666666667
At round 108 training loss: 1.6435714733955684
At round 109 accuracy: 0.5682656826568265
At round 109 training accuracy: 0.5938541666666667
At round 109 training loss: 1.3527659016575975
At round 110 accuracy: 0.5784132841328413
At round 110 training accuracy: 0.6005208333333333
At round 110 training loss: 1.1433248558870401
At round 111 accuracy: 0.5691881918819188
At round 111 training accuracy: 0.5932291666666667
At round 111 training loss: 1.386185789439866
At round 112 accuracy: 0.5673431734317343
At round 112 training accuracy: 0.59375
At round 112 training loss: 1.688193273738434
At round 113 accuracy: 0.566420664206642
At round 113 training accuracy: 0.5946875
At round 113 training loss: 1.5314826242641235
At round 114 accuracy: 0.5719557195571956
At round 114 training accuracy: 0.5933333333333334
At round 114 training loss: 2.000290500231786
At round 115 accuracy: 0.5673431734317343
At round 115 training accuracy: 0.5916666666666667
At round 115 training loss: 1.926234434254196
At round 116 accuracy: 0.5710332103321033
At round 116 training accuracy: 0.59625
At round 116 training loss: 1.6369917080054681
At round 117 accuracy: 0.5673431734317343
At round 117 training accuracy: 0.5927083333333333
At round 117 training loss: 1.4674529177260895
At round 118 accuracy: 0.5867158671586716
At round 118 training accuracy: 0.6088541666666667
At round 118 training loss: 0.9987833743691833
At round 119 accuracy: 0.5904059040590406
At round 119 training accuracy: 0.6134375
At round 119 training loss: 0.9799183557851938
At round 120 accuracy: 0.5673431734317343
At round 120 training accuracy: 0.5907291666666666
At round 120 training loss: 1.7733444591413718
At round 121 accuracy: 0.5645756457564576
At round 121 training accuracy: 0.5895833333333333
At round 121 training loss: 2.245779866941739
At round 122 accuracy: 0.5645756457564576
At round 122 training accuracy: 0.5920833333333333
At round 122 training loss: 1.897755070583274
At round 123 accuracy: 0.5691881918819188
At round 123 training accuracy: 0.5920833333333333
At round 123 training loss: 2.0436526032125886
At round 124 accuracy: 0.5701107011070111
At round 124 training accuracy: 0.5920833333333333
At round 124 training loss: 1.9603341853323704
At round 125 accuracy: 0.5673431734317343
At round 125 training accuracy: 0.5910416666666667
At round 125 training loss: 1.3851227728133866
At round 126 accuracy: 0.5618081180811808
At round 126 training accuracy: 0.589375
At round 126 training loss: 1.5077915531129111
At round 127 accuracy: 0.566420664206642
At round 127 training accuracy: 0.5891666666666666
At round 127 training loss: 1.3651356304937508
At round 128 accuracy: 0.5682656826568265
At round 128 training accuracy: 0.5895833333333333
At round 128 training loss: 1.2975340979618097
At round 129 accuracy: 0.5784132841328413
At round 129 training accuracy: 0.5985416666666666
At round 129 training loss: 1.081453718948566
At round 130 accuracy: 0.6134686346863468
At round 130 training accuracy: 0.6311458333333333
At round 130 training loss: 0.8430470513079005
At round 131 accuracy: 0.5691881918819188
At round 131 training accuracy: 0.5958333333333333
At round 131 training loss: 1.4810757218297417
At round 132 accuracy: 0.577490774907749
At round 132 training accuracy: 0.59875
At round 132 training loss: 1.1600402941492696
At round 133 accuracy: 0.577490774907749
At round 133 training accuracy: 0.5989583333333334
At round 133 training loss: 1.1701290153335624
At round 134 accuracy: 0.5968634686346863
At round 134 training accuracy: 0.6195833333333334
At round 134 training loss: 0.9420486336077253
At round 135 accuracy: 0.5876383763837638
At round 135 training accuracy: 0.6077083333333333
At round 135 training loss: 1.0448099834378808
At round 136 accuracy: 0.584870848708487
At round 136 training accuracy: 0.6059375
At round 136 training loss: 1.1809453287984555
At round 137 accuracy: 0.5747232472324724
At round 137 training accuracy: 0.5935416666666666
At round 137 training loss: 1.5350080748212833
At round 138 accuracy: 0.5747232472324724
At round 138 training accuracy: 0.5967708333333334
At round 138 training loss: 1.211314636754881
At round 139 accuracy: 0.5636531365313653
At round 139 training accuracy: 0.5892708333333333
At round 139 training loss: 2.082517966898158
At round 140 accuracy: 0.566420664206642
At round 140 training accuracy: 0.5919791666666666
At round 140 training loss: 1.8480569555719073
At round 141 accuracy: 0.5673431734317343
At round 141 training accuracy: 0.5914583333333333
At round 141 training loss: 1.5035315254664359
At round 142 accuracy: 0.5793357933579336
At round 142 training accuracy: 0.6032291666666667
At round 142 training loss: 1.227062597721039
At round 143 accuracy: 0.5710332103321033
At round 143 training accuracy: 0.6027083333333333
At round 143 training loss: 1.5060353473504073
At round 144 accuracy: 0.5747232472324724
At round 144 training accuracy: 0.6002083333333333
At round 144 training loss: 1.3591521608503536
At round 145 accuracy: 0.5756457564575646
At round 145 training accuracy: 0.6010416666666667
At round 145 training loss: 1.2108224560079786
At round 146 accuracy: 0.5793357933579336
At round 146 training accuracy: 0.6064583333333333
At round 146 training loss: 1.0597062616283075
At round 147 accuracy: 0.5968634686346863
At round 147 training accuracy: 0.6180208333333334
At round 147 training loss: 0.9382901457309102
At round 148 accuracy: 0.6356088560885609
At round 148 training accuracy: 0.6558333333333334
At round 148 training loss: 0.7626132097855831
At round 149 accuracy: 0.5885608856088561
At round 149 training accuracy: 0.6107291666666667
At round 149 training loss: 0.9512301010719966
At round 150 accuracy: 0.5913284132841329
At round 150 training accuracy: 0.6184375
At round 150 training loss: 0.904645572611286
At round 151 accuracy: 0.577490774907749
At round 151 training accuracy: 0.6008333333333333
At round 151 training loss: 1.1388421292525406
At round 152 accuracy: 0.5793357933579336
At round 152 training accuracy: 0.6002083333333333
At round 152 training loss: 1.1740092638274655
At round 153 accuracy: 0.5618081180811808
At round 153 training accuracy: 0.5901041666666667
At round 153 training loss: 1.5252695905184372
At round 154 accuracy: 0.5581180811808119
At round 154 training accuracy: 0.5840625
At round 154 training loss: 2.586499932015625
At round 155 accuracy: 0.5618081180811808
At round 155 training accuracy: 0.5879166666666666
At round 155 training loss: 2.4189684189716356
At round 156 accuracy: 0.566420664206642
At round 156 training accuracy: 0.5873958333333333
At round 156 training loss: 2.573238755771114
At round 157 accuracy: 0.5673431734317343
At round 157 training accuracy: 0.5903125
At round 157 training loss: 2.620043778406301
At round 158 accuracy: 0.5710332103321033
At round 158 training accuracy: 0.5972916666666667
At round 158 training loss: 2.3822153814020566
At round 159 accuracy: 0.5728782287822878
At round 159 training accuracy: 0.598125
At round 159 training loss: 2.4416937708167823
At round 160 accuracy: 0.5728782287822878
At round 160 training accuracy: 0.5990625
At round 160 training loss: 2.391863648731378
At round 161 accuracy: 0.5738007380073801
At round 161 training accuracy: 0.598125
At round 161 training loss: 1.955909495614857
At round 162 accuracy: 0.5682656826568265
At round 162 training accuracy: 0.5978125
At round 162 training loss: 1.8068279311148217
At round 163 accuracy: 0.5682656826568265
At round 163 training accuracy: 0.5977083333333333
At round 163 training loss: 1.535676848978231
At round 164 accuracy: 0.5756457564575646
At round 164 training accuracy: 0.6003125
At round 164 training loss: 1.4204617592461484
At round 165 accuracy: 0.5701107011070111
At round 165 training accuracy: 0.5967708333333334
At round 165 training loss: 1.9591559047799092
At round 166 accuracy: 0.5701107011070111
At round 166 training accuracy: 0.5967708333333334
At round 166 training loss: 1.707075612101859
At round 167 accuracy: 0.5710332103321033
At round 167 training accuracy: 0.594375
At round 167 training loss: 1.730682780665423
At round 168 accuracy: 0.577490774907749
At round 168 training accuracy: 0.5989583333333334
At round 168 training loss: 1.521917525207585
At round 169 accuracy: 0.5728782287822878
At round 169 training accuracy: 0.5957291666666666
At round 169 training loss: 1.5549291216056251
At round 170 accuracy: 0.566420664206642
At round 170 training accuracy: 0.5928125
At round 170 training loss: 1.4838557631825098
At round 171 accuracy: 0.5691881918819188
At round 171 training accuracy: 0.5926041666666667
At round 171 training loss: 2.030814361582355
At round 172 accuracy: 0.566420664206642
At round 172 training accuracy: 0.5925
At round 172 training loss: 1.7469234211271396
At round 173 accuracy: 0.5738007380073801
At round 173 training accuracy: 0.5988541666666667
At round 173 training loss: 1.4590354809890655
At round 174 accuracy: 0.5784132841328413
At round 174 training accuracy: 0.6026041666666667
At round 174 training loss: 1.2274388246785384
At round 175 accuracy: 0.5839483394833949
At round 175 training accuracy: 0.6054166666666667
At round 175 training loss: 1.1176999789684001
At round 176 accuracy: 0.5821033210332104
At round 176 training accuracy: 0.6051041666666667
At round 176 training loss: 1.1892701026805055
At round 177 accuracy: 0.5765682656826568
At round 177 training accuracy: 0.5992708333333333
At round 177 training loss: 1.5954693051058955
At round 178 accuracy: 0.5765682656826568
At round 178 training accuracy: 0.6009375
At round 178 training loss: 2.4492937585016867
At round 179 accuracy: 0.577490774907749
At round 179 training accuracy: 0.6020833333333333
At round 179 training loss: 2.340361246599738
At round 180 accuracy: 0.5821033210332104
At round 180 training accuracy: 0.6052083333333333
At round 180 training loss: 2.246731167801966
At round 181 accuracy: 0.5802583025830258
At round 181 training accuracy: 0.6053125
At round 181 training loss: 1.984252638662389
At round 182 accuracy: 0.5784132841328413
At round 182 training accuracy: 0.604375
At round 182 training loss: 1.8393061424252422
At round 183 accuracy: 0.577490774907749
At round 183 training accuracy: 0.6025
At round 183 training loss: 1.4328599376204267
At round 184 accuracy: 0.5756457564575646
At round 184 training accuracy: 0.6017708333333334
At round 184 training loss: 1.389435119467477
At round 185 accuracy: 0.5710332103321033
At round 185 training accuracy: 0.6038541666666667
At round 185 training loss: 1.197264065334263
At round 186 accuracy: 0.6088560885608856
At round 186 training accuracy: 0.6335416666666667
At round 186 training loss: 0.8672206954169087
At round 187 accuracy: 0.6863468634686347
At round 187 training accuracy: 0.7117708333333334
At round 187 training loss: 0.6443478000730587
At round 188 accuracy: 0.7149446494464945
At round 188 training accuracy: 0.7461458333333333
At round 188 training loss: 0.5858022515458288
At round 189 accuracy: 0.7130996309963099
At round 189 training accuracy: 0.7451041666666667
At round 189 training loss: 0.5971740588918328
At round 190 accuracy: 0.7149446494464945
At round 190 training accuracy: 0.739375
At round 190 training loss: 0.6058225648318573
At round 191 accuracy: 0.7204797047970479
At round 191 training accuracy: 0.744375
At round 191 training loss: 0.598495145746662
At round 192 accuracy: 0.683579335793358
At round 192 training accuracy: 0.7034375
At round 192 training loss: 0.6745306073614241
At round 193 accuracy: 0.6614391143911439
At round 193 training accuracy: 0.6879166666666666
At round 193 training loss: 0.7084886836388614
At round 194 accuracy: 0.7177121771217713
At round 194 training accuracy: 0.7348958333333333
At round 194 training loss: 0.6159224099079923
At round 195 accuracy: 0.7130996309963099
At round 195 training accuracy: 0.7428125
At round 195 training loss: 0.6049154205721182
At round 196 accuracy: 0.6669741697416974
At round 196 training accuracy: 0.6926041666666667
At round 196 training loss: 0.6886202391576565
At round 197 accuracy: 0.6706642066420664
At round 197 training accuracy: 0.6957291666666666
At round 197 training loss: 0.6821382637839997
At round 198 accuracy: 0.6568265682656826
At round 198 training accuracy: 0.6785416666666667
At round 198 training loss: 0.727515760496026
At round 199 accuracy: 0.6448339483394834
At round 199 training accuracy: 0.666875
At round 199 training loss: 0.7508644629172826
At round 200 accuracy: 0.672509225092251
At round 200 training accuracy: 0.6983333333333334
