PYTHONPATH
2022-10-20 09:36:16.735762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
WARNING:tensorflow:From /home/aig/.conda/envs/tfl/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
Arguments:
	         Jmax : 50
	            L : 40
	            M : 10
	     MC_trial : 50
	            N : 5
	          SNR : 90
	   batch_size : 10
	      dataset : synthetic_1_1
	 drop_percent : 0.0
	   eval_every : 1
	learning_rate : 0.0001
	        model : mclr
	 model_params : (10,)
	           mu : 0
	          nit : 100
	   num_epochs : 20
	    num_iters : 1
	   num_rounds : 200
	    optimizer : fedavg
	         seed : 0
	          set : 2
	          tau : 1
	    threshold : 0.01
	      verbose : 0
Using Federated avg to Train
/home/aig/.conda/envs/tfl/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  warnings.warn('`tf.layers.dense` is deprecated and '
/home/aig/.conda/envs/tfl/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  warnings.warn('`layer.apply` is deprecated and '
2022-10-20 09:36:19.289346: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-10-20 09:36:19.290868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-10-20 09:36:19.389092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 09:36:19.389887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 09:36:19.390624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 09:36:19.391347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:af:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 09:36:19.391395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-10-20 09:36:19.396475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-10-20 09:36:19.396583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-10-20 09:36:19.401196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-10-20 09:36:19.402674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-10-20 09:36:19.408053: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-10-20 09:36:19.410888: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-10-20 09:36:19.420389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-10-20 09:36:19.425153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2022-10-20 09:36:19.425932: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-20 09:36:19.427946: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-10-20 09:36:20.060319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 09:36:20.060807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 09:36:20.061218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 09:36:20.061618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:af:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2022-10-20 09:36:20.061658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-10-20 09:36:20.061691: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-10-20 09:36:20.061705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-10-20 09:36:20.061720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-10-20 09:36:20.061734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-10-20 09:36:20.061747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-10-20 09:36:20.061760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-10-20 09:36:20.061774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-10-20 09:36:20.064694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2022-10-20 09:36:20.064736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-10-20 10:11:26.027329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-10-20 10:11:26.027595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 
2022-10-20 10:11:26.027612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N N N 
2022-10-20 10:11:26.027617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N N N 
2022-10-20 10:11:26.027622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   N N N N 
2022-10-20 10:11:26.027627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   N N N N 
2022-10-20 10:11:26.030491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22430 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:18:00.0, compute capability: 8.6)
2022-10-20 10:11:26.031808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22430 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:3b:00.0, compute capability: 8.6)
2022-10-20 10:11:26.032864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 22430 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:86:00.0, compute capability: 8.6)
2022-10-20 10:11:26.033928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 22430 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6)
2022-10-20 10:11:26.038528: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)
2022-10-20 10:11:26.040479: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400000000 Hz
WARNING:tensorflow:From /home/aig/.conda/envs/tfl/lib/python3.9/site-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`
Incomplete shape.
Incomplete shape.

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================
Incomplete shape.
Incomplete shape.

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/2.40k flops)
  dense/kernel/Initializer/random_uniform (600/1.20k flops)
    dense/kernel/Initializer/random_uniform/mul (600/600 flops)
    dense/kernel/Initializer/random_uniform/sub (1/1 flops)
  dense/kernel/Regularizer/Square (600/600 flops)
  dense/kernel/Regularizer/Sum (599/599 flops)
  dense/kernel/Regularizer/mul (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/Neg (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/mul (1/1 flops)
  sparse_softmax_cross_entropy_loss/num_present/Equal (1/1 flops)

======================End of Report==========================
Training with 10/30 workers ---
sum of K (set==2) 24058 (30,)
try user num: 30, feasible:False None
try user num: 29, feasible:False None
try user num: 28, feasible:False None
try user num: 27, feasible:False None
try user num: 26, feasible:False None
try user num: 25, feasible:False None
try user num: 24, feasible:False None
try user num: 23, feasible:False None
try user num: 22, feasible:False None
try user num: 21, feasible:False None
try user num: 20, feasible:False None
try user num: 19, feasible:False None
try user num: 18, feasible:False None
try user num: 17, feasible:False None
try user num: 16, feasible:False None
try user num: 15, feasible:False None
try user num: 14, feasible:False None
try user num: 13, feasible:False None
try user num: 12, feasible:False None
try user num: 11, feasible:False None
try user num: 10, feasible:True [ 0.249832+0.j       -0.225892-0.150309j  0.772145-0.046531j
  0.064085+0.074851j -0.130382+0.488755j]
WARNING:tensorflow:From /home/aig/NailIt/FedProx/flearn/models/synthetic/mclr.py:58: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Prefer Variable.assign which has equivalent behavior in 2.X.
2022-10-20 10:20:30.178292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
At round 0 accuracy: 0.035977859778597784
At round 0 training accuracy: 0.035104166666666665
At round 0 training loss: 4.849575720814367
At round 1 accuracy: 0.03505535055350553
At round 1 training accuracy: 0.034791666666666665
At round 1 training loss: 3.951518920622766
At round 2 accuracy: 0.03044280442804428
At round 2 training accuracy: 0.0321875
At round 2 training loss: 4.0369634128113585
At round 3 accuracy: 0.033210332103321034
At round 3 training accuracy: 0.03333333333333333
At round 3 training loss: 4.112769321985542
At round 4 accuracy: 0.035977859778597784
At round 4 training accuracy: 0.034895833333333334
At round 4 training loss: 3.2571045299991965
At round 5 accuracy: 0.03874538745387454
At round 5 training accuracy: 0.036458333333333336
At round 5 training loss: 3.237082979468008
At round 6 accuracy: 0.03413284132841329
At round 6 training accuracy: 0.035208333333333335
At round 6 training loss: 3.3249173633133373
At round 7 accuracy: 0.03413284132841329
At round 7 training accuracy: 0.03395833333333333
At round 7 training loss: 3.3278712968404096
At round 8 accuracy: 0.033210332103321034
At round 8 training accuracy: 0.0325
At round 8 training loss: 3.366220874041319
At round 9 accuracy: 0.03505535055350553
At round 9 training accuracy: 0.03375
At round 9 training loss: 2.8982083509117365
At round 10 accuracy: 0.033210332103321034
At round 10 training accuracy: 0.035625
At round 10 training loss: 2.997177771516144
At round 11 accuracy: 0.03690036900369004
At round 11 training accuracy: 0.0359375
At round 11 training loss: 3.0595399632553257
At round 12 accuracy: 0.04059040590405904
At round 12 training accuracy: 0.035625
At round 12 training loss: 2.389504413641989
At round 13 accuracy: 0.045202952029520294
At round 13 training accuracy: 0.0390625
At round 13 training loss: 2.3307158570985
At round 14 accuracy: 0.16512915129151293
At round 14 training accuracy: 0.14291666666666666
At round 14 training loss: 2.001532910565535
At round 15 accuracy: 0.1282287822878229
At round 15 training accuracy: 0.11385416666666667
At round 15 training loss: 2.135657580681145
At round 16 accuracy: 0.09686346863468635
At round 16 training accuracy: 0.08572916666666666
At round 16 training loss: 2.203063046038151
At round 17 accuracy: 0.10977859778597786
At round 17 training accuracy: 0.09510416666666667
At round 17 training loss: 2.1729402191067737
At round 18 accuracy: 0.10055350553505535
At round 18 training accuracy: 0.08885416666666666
At round 18 training loss: 2.1451786859333515
At round 19 accuracy: 0.08394833948339483
At round 19 training accuracy: 0.08
At round 19 training loss: 2.206984671925505
At round 20 accuracy: 0.283210332103321
At round 20 training accuracy: 0.26895833333333335
At round 20 training loss: 1.8613088776543736
At round 21 accuracy: 0.18726937269372693
At round 21 training accuracy: 0.16822916666666668
At round 21 training loss: 1.9402811896800995
At round 22 accuracy: 0.1559040590405904
At round 22 training accuracy: 0.15229166666666666
At round 22 training loss: 1.9945981361096103
At round 23 accuracy: 0.1706642066420664
At round 23 training accuracy: 0.16645833333333335
At round 23 training loss: 2.0692111618071793
At round 24 accuracy: 0.13837638376383765
At round 24 training accuracy: 0.13625
At round 24 training loss: 2.1108026740451655
At round 25 accuracy: 0.12638376383763839
At round 25 training accuracy: 0.13385416666666666
At round 25 training loss: 2.1909749675914645
At round 26 accuracy: 0.12453874538745388
At round 26 training accuracy: 0.135
At round 26 training loss: 2.23516305629164
At round 27 accuracy: 0.12915129151291513
At round 27 training accuracy: 0.1378125
At round 27 training loss: 2.372974470841388
At round 28 accuracy: 0.235239852398524
At round 28 training accuracy: 0.23395833333333332
At round 28 training loss: 1.9024774926528334
At round 29 accuracy: 0.38099630996309963
At round 29 training accuracy: 0.38427083333333334
At round 29 training loss: 1.7204649225374062
At round 30 accuracy: 0.4215867158671587
At round 30 training accuracy: 0.4196875
At round 30 training loss: 1.6229446727782488
At round 31 accuracy: 0.4603321033210332
At round 31 training accuracy: 0.4583333333333333
At round 31 training loss: 1.44935270840923
At round 32 accuracy: 0.4612546125461255
At round 32 training accuracy: 0.459375
At round 32 training loss: 1.3904335214942694
At round 33 accuracy: 0.4769372693726937
At round 33 training accuracy: 0.4640625
At round 33 training loss: 1.3337847342528404
At round 34 accuracy: 0.466789667896679
At round 34 training accuracy: 0.46125
At round 34 training loss: 1.3427013836304347
At round 35 accuracy: 0.46309963099630996
At round 35 training accuracy: 0.45895833333333336
At round 35 training loss: 1.3523735175033411
At round 36 accuracy: 0.4612546125461255
At round 36 training accuracy: 0.45729166666666665
At round 36 training loss: 1.3749524441671868
At round 37 accuracy: 0.477859778597786
At round 37 training accuracy: 0.4708333333333333
At round 37 training loss: 1.3113583676579097
At round 38 accuracy: 0.470479704797048
At round 38 training accuracy: 0.46479166666666666
At round 38 training loss: 1.3293278181863328
At round 39 accuracy: 0.45571955719557194
At round 39 training accuracy: 0.45427083333333335
At round 39 training loss: 1.4138509623209636
At round 40 accuracy: 0.4584870848708487
At round 40 training accuracy: 0.4555208333333333
At round 40 training loss: 1.4128101710850993
At round 41 accuracy: 0.4575645756457565
At round 41 training accuracy: 0.4533333333333333
At round 41 training loss: 1.3917884578555821
At round 42 accuracy: 0.4640221402214022
At round 42 training accuracy: 0.4571875
At round 42 training loss: 1.4382578202833731
At round 43 accuracy: 0.4621771217712177
At round 43 training accuracy: 0.4586458333333333
At round 43 training loss: 1.341536354434987
At round 44 accuracy: 0.4612546125461255
At round 44 training accuracy: 0.458125
At round 44 training loss: 1.4177284767106175
At round 45 accuracy: 0.46863468634686345
At round 45 training accuracy: 0.4630208333333333
At round 45 training loss: 1.476570587841173
At round 46 accuracy: 0.46955719557195574
At round 46 training accuracy: 0.4658333333333333
At round 46 training loss: 1.4900745524279773
At round 47 accuracy: 0.477859778597786
At round 47 training accuracy: 0.47072916666666664
At round 47 training loss: 1.5002625429940721
At round 48 accuracy: 0.477859778597786
At round 48 training accuracy: 0.47458333333333336
At round 48 training loss: 1.3229595318126182
At round 49 accuracy: 0.47878228782287824
At round 49 training accuracy: 0.47791666666666666
At round 49 training loss: 1.2730913250955442
At round 50 accuracy: 0.5166051660516605
At round 50 training accuracy: 0.504375
At round 50 training loss: 1.180188279071202
At round 51 accuracy: 0.5129151291512916
At round 51 training accuracy: 0.5053125
At round 51 training loss: 1.186798507447044
At round 52 accuracy: 0.5212177121771218
At round 52 training accuracy: 0.508125
At round 52 training loss: 1.1884674507814148
At round 53 accuracy: 0.5083025830258303
At round 53 training accuracy: 0.4990625
At round 53 training loss: 1.181871404523651
At round 54 accuracy: 0.5101476014760148
At round 54 training accuracy: 0.49916666666666665
At round 54 training loss: 1.1797502230418224
At round 55 accuracy: 0.496309963099631
At round 55 training accuracy: 0.4920833333333333
At round 55 training loss: 1.2008682402968407
At round 56 accuracy: 0.5
At round 56 training accuracy: 0.4972916666666667
At round 56 training loss: 1.1994918464807172
At round 57 accuracy: 0.5046125461254612
At round 57 training accuracy: 0.4984375
At round 57 training loss: 1.200522221295784
At round 58 accuracy: 0.522140221402214
At round 58 training accuracy: 0.5120833333333333
At round 58 training loss: 1.1764406444815299
At round 59 accuracy: 0.544280442804428
At round 59 training accuracy: 0.5234375
At round 59 training loss: 1.132581673854341
At round 60 accuracy: 0.511070110701107
At round 60 training accuracy: 0.5042708333333333
At round 60 training loss: 1.182976878726234
At round 61 accuracy: 0.507380073800738
At round 61 training accuracy: 0.5021875
At round 61 training loss: 1.2015169387993714
At round 62 accuracy: 0.5129151291512916
At round 62 training accuracy: 0.5096875
At round 62 training loss: 1.187022699241837
At round 63 accuracy: 0.5138376383763837
At round 63 training accuracy: 0.5066666666666667
At round 63 training loss: 1.1906570912649235
At round 64 accuracy: 0.5064575645756457
At round 64 training accuracy: 0.5023958333333334
At round 64 training loss: 1.1757555126585066
At round 65 accuracy: 0.507380073800738
At round 65 training accuracy: 0.5071875
At round 65 training loss: 1.1494736041501163
At round 66 accuracy: 0.518450184501845
At round 66 training accuracy: 0.511875
At round 66 training loss: 1.1461436213118334
At round 67 accuracy: 0.5322878228782287
At round 67 training accuracy: 0.5209375
At round 67 training loss: 1.1435941313331326
At round 68 accuracy: 0.525830258302583
At round 68 training accuracy: 0.5155208333333333
At round 68 training loss: 1.1436220669125516
At round 69 accuracy: 0.5230627306273062
At round 69 training accuracy: 0.5176041666666666
At round 69 training loss: 1.1436976575292648
At round 70 accuracy: 0.514760147601476
At round 70 training accuracy: 0.5115625
At round 70 training loss: 1.1436931240372359
At round 71 accuracy: 0.5156826568265682
At round 71 training accuracy: 0.5128125
At round 71 training loss: 1.1413510786245267
At round 72 accuracy: 0.522140221402214
At round 72 training accuracy: 0.5183333333333333
At round 72 training loss: 1.1364253560453654
At round 73 accuracy: 0.514760147601476
At round 73 training accuracy: 0.5113541666666667
At round 73 training loss: 1.181970037277788
At round 74 accuracy: 0.5295202952029521
At round 74 training accuracy: 0.5219791666666667
At round 74 training loss: 1.1047683859368165
At round 75 accuracy: 0.5175276752767528
At round 75 training accuracy: 0.5134375
At round 75 training loss: 1.1391905843590697
At round 76 accuracy: 0.540590405904059
At round 76 training accuracy: 0.5315625
At round 76 training loss: 1.061508220123748
At round 77 accuracy: 0.5627306273062731
At round 77 training accuracy: 0.5473958333333333
At round 77 training loss: 1.0413185253553092
At round 78 accuracy: 0.559040590405904
At round 78 training accuracy: 0.5458333333333333
At round 78 training loss: 1.0550449554870527
At round 79 accuracy: 0.5535055350553506
At round 79 training accuracy: 0.5465625
At round 79 training loss: 1.065691757214566
At round 80 accuracy: 0.5581180811808119
At round 80 training accuracy: 0.5508333333333333
At round 80 training loss: 1.0637364423833788
At round 81 accuracy: 0.5599630996309963
At round 81 training accuracy: 0.5515625
At round 81 training loss: 1.0684701367033025
At round 82 accuracy: 0.5498154981549815
At round 82 training accuracy: 0.54375
At round 82 training loss: 1.0917216603085398
At round 83 accuracy: 0.5719557195571956
At round 83 training accuracy: 0.5573958333333333
At round 83 training loss: 1.032582220652451
At round 84 accuracy: 0.5618081180811808
At round 84 training accuracy: 0.5501041666666666
At round 84 training loss: 1.0272498796818157
At round 85 accuracy: 0.5571955719557196
At round 85 training accuracy: 0.54875
At round 85 training loss: 1.0277140990210076
At round 86 accuracy: 0.5479704797047971
At round 86 training accuracy: 0.5403125
At round 86 training loss: 1.0470146087060372
At round 87 accuracy: 0.5830258302583026
At round 87 training accuracy: 0.5664583333333333
At round 87 training loss: 0.9909616015292704
At round 88 accuracy: 0.5959409594095941
At round 88 training accuracy: 0.5696875
At round 88 training loss: 0.9861878058873117
At round 89 accuracy: 0.6070110701107011
At round 89 training accuracy: 0.5886458333333333
At round 89 training loss: 0.9723004898770402
At round 90 accuracy: 0.6023985239852399
At round 90 training accuracy: 0.579375
At round 90 training loss: 0.9850772711541503
At round 91 accuracy: 0.6153136531365314
At round 91 training accuracy: 0.5955208333333334
At round 91 training loss: 0.9559691240824759
At round 92 accuracy: 0.6190036900369004
At round 92 training accuracy: 0.6005208333333333
At round 92 training loss: 0.9511080252223959
At round 93 accuracy: 0.6171586715867159
At round 93 training accuracy: 0.5996875
At round 93 training loss: 0.9472134337791552
At round 94 accuracy: 0.6245387453874539
At round 94 training accuracy: 0.6070833333333333
At round 94 training loss: 0.9442473933349053
At round 95 accuracy: 0.6226937269372693
At round 95 training accuracy: 0.60625
At round 95 training loss: 0.9353917764561872
At round 96 accuracy: 0.6245387453874539
At round 96 training accuracy: 0.6027083333333333
At round 96 training loss: 0.9361218720022589
At round 97 accuracy: 0.6254612546125461
At round 97 training accuracy: 0.6084375
At round 97 training loss: 0.9330844070917617
At round 98 accuracy: 0.6337638376383764
At round 98 training accuracy: 0.6163541666666666
At round 98 training loss: 0.9280428751340757
At round 99 accuracy: 0.6300738007380073
At round 99 training accuracy: 0.6122916666666667
At round 99 training loss: 0.9298060161992907
At round 100 accuracy: 0.6273062730627307
At round 100 training accuracy: 0.6101041666666667
At round 100 training loss: 0.928589902628834
At round 101 accuracy: 0.6125461254612546
At round 101 training accuracy: 0.5911458333333334
At round 101 training loss: 0.9453669608167062
At round 102 accuracy: 0.6254612546125461
At round 102 training accuracy: 0.6022916666666667
At round 102 training loss: 0.9416730042236546
At round 103 accuracy: 0.6254612546125461
At round 103 training accuracy: 0.6079166666666667
At round 103 training loss: 0.9409184529849639
At round 104 accuracy: 0.6420664206642066
At round 104 training accuracy: 0.6230208333333334
At round 104 training loss: 0.9110157396271825
At round 105 accuracy: 0.6448339483394834
At round 105 training accuracy: 0.6319791666666666
At round 105 training loss: 0.9048652226291597
At round 106 accuracy: 0.6420664206642066
At round 106 training accuracy: 0.6301041666666667
At round 106 training loss: 0.9064902819631
At round 107 accuracy: 0.6494464944649446
At round 107 training accuracy: 0.6475
At round 107 training loss: 0.8843846537762632
At round 108 accuracy: 0.6457564575645757
At round 108 training accuracy: 0.6419791666666667
At round 108 training loss: 0.8873714124783874
At round 109 accuracy: 0.6365313653136532
At round 109 training accuracy: 0.6194791666666667
At round 109 training loss: 0.9033110438815007
At round 110 accuracy: 0.6420664206642066
At round 110 training accuracy: 0.6242708333333333
At round 110 training loss: 0.9009341305308044
At round 111 accuracy: 0.6439114391143912
At round 111 training accuracy: 0.6234375
At round 111 training loss: 0.8998558388619373
At round 112 accuracy: 0.6457564575645757
At round 112 training accuracy: 0.6297916666666666
At round 112 training loss: 0.8956925654752801
At round 113 accuracy: 0.6429889298892989
At round 113 training accuracy: 0.629375
At round 113 training loss: 0.8944717002566904
At round 114 accuracy: 0.6457564575645757
At round 114 training accuracy: 0.6313541666666667
At round 114 training loss: 0.893186051119119
At round 115 accuracy: 0.6540590405904059
At round 115 training accuracy: 0.6452083333333334
At round 115 training loss: 0.8736490196703622
At round 116 accuracy: 0.6522140221402214
At round 116 training accuracy: 0.6458333333333334
At round 116 training loss: 0.8731355099162708
At round 117 accuracy: 0.6669741697416974
At round 117 training accuracy: 0.6752083333333333
At round 117 training loss: 0.8470654431078583
At round 118 accuracy: 0.6660516605166051
At round 118 training accuracy: 0.6909375
At round 118 training loss: 0.8344905093902101
At round 119 accuracy: 0.6632841328413284
At round 119 training accuracy: 0.69125
At round 119 training loss: 0.8335177783792218
At round 120 accuracy: 0.6697416974169742
At round 120 training accuracy: 0.6917708333333333
At round 120 training loss: 0.8320307201364389
At round 121 accuracy: 0.6706642066420664
At round 121 training accuracy: 0.6953125
At round 121 training loss: 0.8304816457629204
At round 122 accuracy: 0.672509225092251
At round 122 training accuracy: 0.6954166666666667
At round 122 training loss: 0.8298405904229731
At round 123 accuracy: 0.6743542435424354
At round 123 training accuracy: 0.695625
At round 123 training loss: 0.8293563401109229
At round 124 accuracy: 0.6623616236162362
At round 124 training accuracy: 0.6898958333333334
At round 124 training loss: 0.8312037624698132
At round 125 accuracy: 0.6688191881918819
At round 125 training accuracy: 0.6916666666666667
At round 125 training loss: 0.8244132308010012
At round 126 accuracy: 0.6678966789667896
At round 126 training accuracy: 0.6914583333333333
At round 126 training loss: 0.8242617541924119
At round 127 accuracy: 0.6706642066420664
At round 127 training accuracy: 0.6940625
At round 127 training loss: 0.8208776249426106
At round 128 accuracy: 0.6697416974169742
At round 128 training accuracy: 0.6946875
At round 128 training loss: 0.815560311799248
At round 129 accuracy: 0.6678966789667896
At round 129 training accuracy: 0.6929166666666666
At round 129 training loss: 0.8149326712979624
At round 130 accuracy: 0.6743542435424354
At round 130 training accuracy: 0.6969791666666667
At round 130 training loss: 0.8102721039516231
At round 131 accuracy: 0.6743542435424354
At round 131 training accuracy: 0.69875
At round 131 training loss: 0.8078875912881146
At round 132 accuracy: 0.6743542435424354
At round 132 training accuracy: 0.6982291666666667
At round 132 training loss: 0.8043507630378008
At round 133 accuracy: 0.6743542435424354
At round 133 training accuracy: 0.7005208333333334
At round 133 training loss: 0.8013822431024163
At round 134 accuracy: 0.672509225092251
At round 134 training accuracy: 0.6988541666666667
At round 134 training loss: 0.7989888370037079
At round 135 accuracy: 0.6715867158671587
At round 135 training accuracy: 0.6992708333333333
At round 135 training loss: 0.7982236830207209
At round 136 accuracy: 0.672509225092251
At round 136 training accuracy: 0.700625
At round 136 training loss: 0.7962126215516279
At round 137 accuracy: 0.6697416974169742
At round 137 training accuracy: 0.7003125
At round 137 training loss: 0.796043031938995
At round 138 accuracy: 0.6734317343173432
At round 138 training accuracy: 0.7020833333333333
At round 138 training loss: 0.7923731157525132
At round 139 accuracy: 0.6688191881918819
At round 139 training accuracy: 0.6992708333333333
At round 139 training loss: 0.7911224060660849
At round 140 accuracy: 0.672509225092251
At round 140 training accuracy: 0.7035416666666666
At round 140 training loss: 0.7880989505567898
At round 141 accuracy: 0.6752767527675276
At round 141 training accuracy: 0.7052083333333333
At round 141 training loss: 0.7862124696746469
At round 142 accuracy: 0.6761992619926199
At round 142 training accuracy: 0.7042708333333333
At round 142 training loss: 0.7858532333342979
At round 143 accuracy: 0.6771217712177122
At round 143 training accuracy: 0.7065625
At round 143 training loss: 0.7831923784657071
At round 144 accuracy: 0.6817343173431735
At round 144 training accuracy: 0.7076041666666667
At round 144 training loss: 0.7822343183433016
At round 145 accuracy: 0.6798892988929889
At round 145 training accuracy: 0.7072916666666667
At round 145 training loss: 0.7810426526485632
At round 146 accuracy: 0.6771217712177122
At round 146 training accuracy: 0.7075
At round 146 training loss: 0.7771134431784351
At round 147 accuracy: 0.6771217712177122
At round 147 training accuracy: 0.7086458333333333
At round 147 training loss: 0.7747892479598523
At round 148 accuracy: 0.6845018450184502
At round 148 training accuracy: 0.7086458333333333
At round 148 training loss: 0.7734223579398046
At round 149 accuracy: 0.6808118081180812
At round 149 training accuracy: 0.7108333333333333
At round 149 training loss: 0.7722278280152629
At round 150 accuracy: 0.6808118081180812
At round 150 training accuracy: 0.7114583333333333
At round 150 training loss: 0.7704187826346606
At round 151 accuracy: 0.6854243542435424
At round 151 training accuracy: 0.7115625
At round 151 training loss: 0.7688434564601629
At round 152 accuracy: 0.6826568265682657
At round 152 training accuracy: 0.7136458333333333
At round 152 training loss: 0.7669116165333738
At round 153 accuracy: 0.6817343173431735
At round 153 training accuracy: 0.7135416666666666
At round 153 training loss: 0.7648460222470264
At round 154 accuracy: 0.6789667896678967
At round 154 training accuracy: 0.7133333333333334
At round 154 training loss: 0.7636925372108817
At round 155 accuracy: 0.6826568265682657
At round 155 training accuracy: 0.7122916666666667
At round 155 training loss: 0.7609841412678361
At round 156 accuracy: 0.683579335793358
At round 156 training accuracy: 0.7119791666666667
At round 156 training loss: 0.7605203723379721
At round 157 accuracy: 0.683579335793358
At round 157 training accuracy: 0.7127083333333334
At round 157 training loss: 0.759203599585841
At round 158 accuracy: 0.6881918819188192
At round 158 training accuracy: 0.7135416666666666
At round 158 training loss: 0.7576876141503454
At round 159 accuracy: 0.6854243542435424
At round 159 training accuracy: 0.7129166666666666
At round 159 training loss: 0.7567280320761104
At round 160 accuracy: 0.6845018450184502
At round 160 training accuracy: 0.7135416666666666
At round 160 training loss: 0.755839269803837
At round 161 accuracy: 0.6789667896678967
At round 161 training accuracy: 0.7133333333333334
At round 161 training loss: 0.755205720551312
At round 162 accuracy: 0.6845018450184502
At round 162 training accuracy: 0.7129166666666666
At round 162 training loss: 0.754159655344362
At round 163 accuracy: 0.6845018450184502
At round 163 training accuracy: 0.71375
At round 163 training loss: 0.7515342088416219
At round 164 accuracy: 0.6872693726937269
At round 164 training accuracy: 0.7147916666666667
At round 164 training loss: 0.750529678867509
At round 165 accuracy: 0.6872693726937269
At round 165 training accuracy: 0.7158333333333333
At round 165 training loss: 0.7485167840588838
At round 166 accuracy: 0.6872693726937269
At round 166 training accuracy: 0.7153125
At round 166 training loss: 0.7477911578274021
At round 167 accuracy: 0.6854243542435424
At round 167 training accuracy: 0.7151041666666667
At round 167 training loss: 0.747043703092883
At round 168 accuracy: 0.6872693726937269
At round 168 training accuracy: 0.7164583333333333
At round 168 training loss: 0.7454648846232643
At round 169 accuracy: 0.6881918819188192
At round 169 training accuracy: 0.716875
At round 169 training loss: 0.744692810419947
At round 170 accuracy: 0.6872693726937269
At round 170 training accuracy: 0.7160416666666667
At round 170 training loss: 0.7439073331095278
At round 171 accuracy: 0.690959409594096
At round 171 training accuracy: 0.7167708333333334
At round 171 training loss: 0.7433518191954742
At round 172 accuracy: 0.6891143911439115
At round 172 training accuracy: 0.7161458333333334
At round 172 training loss: 0.7421667004469782
At round 173 accuracy: 0.6891143911439115
At round 173 training accuracy: 0.7161458333333334
At round 173 training loss: 0.7408413418165097
At round 174 accuracy: 0.6937269372693727
At round 174 training accuracy: 0.7154166666666667
At round 174 training loss: 0.7414157785413166
At round 175 accuracy: 0.6955719557195572
At round 175 training accuracy: 0.7157291666666666
At round 175 training loss: 0.740546643078948
At round 176 accuracy: 0.698339483394834
At round 176 training accuracy: 0.7180208333333333
At round 176 training loss: 0.7381316612040003
At round 177 accuracy: 0.7020295202952029
At round 177 training accuracy: 0.7148958333333333
At round 177 training loss: 0.7383165321312845
At round 178 accuracy: 0.6992619926199262
At round 178 training accuracy: 0.7145833333333333
At round 178 training loss: 0.7388102493000527
At round 179 accuracy: 0.698339483394834
At round 179 training accuracy: 0.7142708333333333
At round 179 training loss: 0.7383649916481226
At round 180 accuracy: 0.6964944649446494
At round 180 training accuracy: 0.7136458333333333
At round 180 training loss: 0.7385148461908102
At round 181 accuracy: 0.7020295202952029
At round 181 training accuracy: 0.7177083333333333
At round 181 training loss: 0.7341869862222423
At round 182 accuracy: 0.7029520295202952
At round 182 training accuracy: 0.71625
At round 182 training loss: 0.733277095699062
At round 183 accuracy: 0.7029520295202952
At round 183 training accuracy: 0.7178125
At round 183 training loss: 0.7316353075578809
At round 184 accuracy: 0.7020295202952029
At round 184 training accuracy: 0.718125
At round 184 training loss: 0.7293465885333716
At round 185 accuracy: 0.7038745387453874
At round 185 training accuracy: 0.7204166666666667
At round 185 training loss: 0.7266433147837719
At round 186 accuracy: 0.7011070110701108
At round 186 training accuracy: 0.7202083333333333
At round 186 training loss: 0.7252680551446974
At round 187 accuracy: 0.7038745387453874
At round 187 training accuracy: 0.7204166666666667
At round 187 training loss: 0.7249521500275781
At round 188 accuracy: 0.7047970479704797
At round 188 training accuracy: 0.7194791666666667
At round 188 training loss: 0.7254357543370376
At round 189 accuracy: 0.7038745387453874
At round 189 training accuracy: 0.7208333333333333
At round 189 training loss: 0.7238998058034728
At round 190 accuracy: 0.7020295202952029
At round 190 training accuracy: 0.7128125
At round 190 training loss: 0.7276749857980758
At round 191 accuracy: 0.698339483394834
At round 191 training accuracy: 0.713125
At round 191 training loss: 0.7266843415734668
At round 192 accuracy: 0.7047970479704797
At round 192 training accuracy: 0.719375
At round 192 training loss: 0.7231790495570749
At round 193 accuracy: 0.7066420664206642
At round 193 training accuracy: 0.7182291666666667
At round 193 training loss: 0.722948190276511
At round 194 accuracy: 0.705719557195572
At round 194 training accuracy: 0.7216666666666667
At round 194 training loss: 0.7202916318116088
At round 195 accuracy: 0.7047970479704797
At round 195 training accuracy: 0.72125
At round 195 training loss: 0.7186843351026376
At round 196 accuracy: 0.705719557195572
At round 196 training accuracy: 0.7204166666666667
At round 196 training loss: 0.7183542133867741
At round 197 accuracy: 0.7047970479704797
At round 197 training accuracy: 0.7207291666666666
At round 197 training loss: 0.7179960528497273
At round 198 accuracy: 0.709409594095941
At round 198 training accuracy: 0.7215625
At round 198 training loss: 0.7175436671636999
At round 199 accuracy: 0.7066420664206642
At round 199 training accuracy: 0.7245833333333334
At round 199 training loss: 0.7139387628777574
At round 200 accuracy: 0.705719557195572
At round 200 training accuracy: 0.7251041666666667
